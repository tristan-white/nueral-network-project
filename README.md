# Write Up

## Background

As the study of machine learning has grown, it's been discovered that neural networks are able to easily solve problems that were once considered non-trivial such as image classification or speech recognition. With the notion of using systems that utilize these neural nets to solve real-world problems comes a desire to guarantee that these systems are sufficiently secure against adversaries who are interested in methods that would cause neural nets to misclassify their inputs.

## Project

To explore how adversarial attacks can successfully cause neural networks to behave in unexpected ways, I began with a pre-trained neural net that could classify images from the MNIST database of handwritten digits. 
